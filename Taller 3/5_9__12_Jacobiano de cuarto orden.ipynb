{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e30075b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from inspect import signature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b28d6193",
   "metadata": {},
   "source": [
    "Usando que el operador de derivada central de orden $O(h^4)$ est√° dado por: \n",
    "\n",
    "$$\n",
    "f'(x) \\approx \\frac{-f(x+2h) + 8f(x+h) - 8f(x-h) + f(x-2h)}{12h}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e945c1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def func1(x1,x2,x3):\n",
    "    return 6*x1 -2*np.cos(x2*x3) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aae08bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def func2(x1,x2,x3):\n",
    "    return 9*x2 +np.sqrt(x1**2 + np.sin(x3) + 1.06) + 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55d39d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def func3(x1,x2,x3):\n",
    "    return 60*x3 + 3*np.exp(-x1*x2) +10*np.pi-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58952076",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Function(f1,f2,f3):\n",
    "    return (f1, f2, f3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "91a9ddfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "F = Function(func1,func2,func3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d3a45f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GradF4(F, x1,x2,x3, h= 0.01): \n",
    "    grad = np.array([0.,0.,0.])\n",
    "    \n",
    "    grad[0] = (-F(x1+2*h,x2,x3) + 8*F(x1+h,x2,x3) - 8*F(x1-h,x2,x3) + F(x1-2*h,x2,x3))/(12*h)\n",
    "    grad[1] = (-F(x1,x2+2*h,x3) + 8*F(x1,x2+h,x3) - 8*F(x1,x2-h,x3) + F(x1,x2-2*h,x3))/(12*h)\n",
    "    grad[2] = (-F(x1,x2,x3+2*h) + 8*F(x1,x2,x3+h) - 8*F(x1,x2,x3-h) + F(x1,x2,x3-2*h))/(12*h)\n",
    "    \n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3a368fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GradF2(F, x1,x2,x3, h= 0.01): \n",
    "    grad = np.array([0.,0.,0.])\n",
    "    \n",
    "    grad[0] = (F(x1+h,x2,x3) - F(x1-h,x2,x3))/(2*h)\n",
    "    grad[1] = (F(x1,x2+h,x3) - F(x1,x2-h,x3))/(2*h)\n",
    "    grad[2] = (F(x1,x2,x3+h) - F(x1,x2,x3-h))/(2*h)\n",
    "    \n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "93538f1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6.        , 0.24740396, 0.24740396])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dfx = GradF4(F[0],0.5,0.5,0.5)\n",
    "Dfx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "88a612f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Jacobian(F,x1,x2,x3,o4 = True, h=0.01):\n",
    "    Jacobian = np.zeros((len(F),1), dtype=np.ndarray)\n",
    "    \n",
    "    for i in range (len(F)):\n",
    "        if o4:\n",
    "            Jacobian[i,0] = GradF4(F[i],x1,x2,x3)\n",
    "        else:\n",
    "            Jacobian[i,0] = GradF2(F[i],x1,x2,x3,h)\n",
    "    return Jacobian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2258e957",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[array([6.        , 0.24740396, 0.24740396])]\n",
      " [array([0.37377753, 9.        , 0.32802064])]\n",
      " [array([-1.16820117, -1.16820117, 60.        ])]] \n",
      "\n",
      "[[array([6.        , 0.24740293, 0.24740293])]\n",
      " [array([0.37376854, 9.        , 0.32801836])]\n",
      " [array([-1.16820604, -1.16820604, 60.        ])]]\n"
     ]
    }
   ],
   "source": [
    "j4 = Jacobian(F, 0.5, 0.5, 0.5)\n",
    "print(j4,\"\\n\")\n",
    "\n",
    "j2 = Jacobian(F, 0.5, 0.5, 0.5, o4 = False)\n",
    "print(j2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91225ed4",
   "metadata": {},
   "source": [
    "considerando que al usar el metodo de derivada de orden 4 el error es de $0.01^4$, entonces para que al usar el metodo de derivada de orden 2 se debe usar un h tal que $h^2 = 0.01^4$. De lo anterior se desprende que, para que ambos metodos tengan el mismo error, h debe ser 0.0001 para el metodo de derivada de orden 2. Lo anterior se verifica a continuacion: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "636c85c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[array([6.        , 0.24740396, 0.24740396])]\n",
      " [array([0.37377753, 9.        , 0.32802064])]\n",
      " [array([-1.16820118, -1.16820118, 60.        ])]]\n"
     ]
    }
   ],
   "source": [
    "j2 = Jacobian(F, 0.5, 0.5, 0.5, o4 = False, h=0.0001)\n",
    "print(j2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
